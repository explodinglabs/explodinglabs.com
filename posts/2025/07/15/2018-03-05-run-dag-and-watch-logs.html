<div class="wide-logos">
  <p><img src="/posts/assets/airflow.png" alt="airflow" /></p>
</div>

<p>The command to trigger an Airflow dag is simply:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow trigger_dag my-dag
</code></pre></div></div>

<p>But I also want to watch the logs in the terminal. Trouble is, each time a task is run a new directory and file is created. Something like:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~/airflow/logs/my-dag/my-task/2018-03-06T09:59:10.427477/1.log
</code></pre></div></div>

<p>This makes it hard to tail-follow the logs. Thankfully, starting from Airflow
1.9, logging can be configured easily, allowing you to put all of a dag’s logs
into one file.</p>

<div class="warning">
  <p>If you make this change, you won’t be able to view task logs in the web UI,
because the UI expects log filenames to be in the normal format.</p>
</div>

<div class="warning">
  <p>Logging to a single file is useful for development (using the
SequentialExecutor), but it won’t work in production because issues
will arise when multiple tasks attempt to write to the same log file at once.</p>
</div>

<h2 id="easy-solution">Easy Solution</h2>

<div class="warning">
  <p>Requires Airflow 1.10+</p>
</div>

<p>Set the <code class="language-plaintext highlighter-rouge">FILENAME_TEMPLATE</code> setting.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">AIRFLOW__CORE__LOG_FILENAME_TEMPLATE</span><span class="o">=</span><span class="s2">"{{ ti.dag_id }}.log"</span>
</code></pre></div></div>

<h2 id="advanced-solution---recommended">Advanced Solution - Recommended</h2>

<div class="warning">
  <p>Requires Airflow 1.9+</p>
</div>

<p>Since Airflow 1.9, logging is configured Pythonically.</p>

<p>Grab Airflow’s default log config, <code class="language-plaintext highlighter-rouge">airflow_local_settings.py</code>, and copy it
somewhere in your <code class="language-plaintext highlighter-rouge">PYTHONPATH</code>.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-O</span> https://raw.githubusercontent.com/apache/incubator-airflow/master/airflow/config_templates/airflow_local_settings.py
<span class="nb">cp </span>airflow_local_settings.py <span class="nv">$AIRFLOW__CORE__DAGS_FOLDER</span>
</code></pre></div></div>

<p>Set the logging_config_class setting. (Make sure this is set in both your
scheduler and worker’s environments). (Alternatively set the related setting in
airflow.cfg.)</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">AIRFLOW__CORE__LOGGING_CONFIG_CLASS</span><span class="o">=</span>airflow_local_settings.DEFAULT_LOGGING_CONFIG
</code></pre></div></div>

<p>Now you can configure logging to your liking.</p>

<p>Edit airflow_local_settings.py, changing <code class="language-plaintext highlighter-rouge">FILENAME_TEMPLATE</code> to:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FILENAME_TEMPLATE <span class="o">=</span> <span class="s1">'{{ ti.dag_id }}.log'</span>
</code></pre></div></div>

<p>You should now get all of a dag log output in a single file.</p>

<h2 id="tailing-the-logs">Tailing the logs</h2>

<p>Start the scheduler and trigger a dag.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow scheduler
airflow trigger_dag my-dag
</code></pre></div></div>

<p>Watch the output with <code class="language-plaintext highlighter-rouge">tail -f</code>.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tail</span> <span class="nt">-f</span> ~/airflow/logs/my-dag.log
</code></pre></div></div>
